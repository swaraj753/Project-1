{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "#scrap code\n",
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "import logging\n",
        "from typing import List, Dict\n",
        "\n",
        "class GitHubScraper:\n",
        "    def __init__(self, token: str):\n",
        "        self.headers = {\n",
        "            'Authorization': f'token {token}',\n",
        "            'Accept': 'application/vnd.github.v3+json'\n",
        "        }\n",
        "        self.base_url = 'https://api.github.com'\n",
        "\n",
        "        # Setup logging\n",
        "        logging.basicConfig(\n",
        "            level=logging.INFO,\n",
        "            format='%(asctime)s - %(levelname)s - %(message)s'\n",
        "        )\n",
        "        self.logger = logging.getLogger(__name__)\n",
        "\n",
        "    def _make_request(self, url: str, params: dict = None) -> Dict:\n",
        "        while True:\n",
        "            response = requests.get(url, headers=self.headers, params=params)\n",
        "            if response.status_code == 200:\n",
        "                return response.json()\n",
        "            elif response.status_code == 403:\n",
        "                reset_time = int(response.headers.get('X-RateLimit-Reset', 0))\n",
        "                sleep_time = max(reset_time - time.time(), 0) + 1\n",
        "                self.logger.warning(f\"Rate limit hit. Sleeping for {sleep_time} seconds\")\n",
        "                time.sleep(sleep_time)\n",
        "            else:\n",
        "                self.logger.error(f\"Error {response.status_code}: {response.text}\")\n",
        "                response.raise_for_status()\n",
        "\n",
        "    def clean_company_name(self, company: str) -> str:\n",
        "        if not company:\n",
        "            return \"\"\n",
        "        cleaned = company.strip().lstrip('@')\n",
        "        return cleaned.upper()\n",
        "\n",
        "    def search_users(self, location: str, min_followers: int) -> List[Dict]:\n",
        "        users = []\n",
        "        page = 1\n",
        "\n",
        "        while True:\n",
        "            self.logger.info(f\"Fetching users page {page}\")\n",
        "            query = f\"location:{location} followers:>={min_followers}\"\n",
        "            params = {'q': query, 'per_page': 100, 'page': page}\n",
        "            url = f\"{self.base_url}/search/users\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response['items']:\n",
        "                break\n",
        "\n",
        "            self.logger.info(f\"Found {len(response['items'])} users on page {page}\")\n",
        "\n",
        "            for user in response['items']:\n",
        "                user_data = self._make_request(user['url'])\n",
        "                cleaned_data = {\n",
        "                    'login': user_data['login'],\n",
        "                    'name': user_data['name'] if user_data['name'] else \"\",\n",
        "                    'company': self.clean_company_name(user_data.get('company')),\n",
        "                    'location': user_data['location'] if user_data['location'] else \"\",\n",
        "                    'email': user_data['email'] if user_data['email'] else \"\",\n",
        "                    'hireable': user_data['hireable'] if user_data['hireable'] is not None else False,\n",
        "                    'bio': user_data['bio'] if user_data['bio'] else \"\",\n",
        "                    'public_repos': user_data['public_repos'],\n",
        "                    'followers': user_data['followers'],\n",
        "                    'following': user_data['following'],\n",
        "                    'created_at': user_data['created_at']\n",
        "                }\n",
        "                users.append(cleaned_data)\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        self.logger.info(f\"Total users fetched: {len(users)}\")\n",
        "        return users\n",
        "\n",
        "    def get_user_repositories(self, username: str, max_repos: int = 500) -> List[Dict]:\n",
        "        repos = []\n",
        "        page = 1\n",
        "\n",
        "        while len(repos) < max_repos:\n",
        "            self.logger.info(f\"Fetching repositories for {username}, page {page}\")\n",
        "            params = {'sort': 'pushed', 'direction': 'desc', 'per_page': 100, 'page': page}\n",
        "            url = f\"{self.base_url}/users/{username}/repos\"\n",
        "            response = self._make_request(url, params)\n",
        "\n",
        "            if not response:\n",
        "                break\n",
        "\n",
        "            for repo in response:\n",
        "                repo_data = {\n",
        "                    'login': username,\n",
        "                    'full_name': repo['full_name'],\n",
        "                    'created_at': repo['created_at'],\n",
        "                    'stargazers_count': repo['stargazers_count'],\n",
        "                    'watchers_count': repo['watchers_count'],\n",
        "                    'language': repo['language'] if repo['language'] else \"\",\n",
        "                    'has_projects': repo['has_projects'],\n",
        "                    'has_wiki': repo['has_wiki'],\n",
        "                    'license_name': repo['license']['key'] if repo.get('license') else \"\"\n",
        "                }\n",
        "                repos.append(repo_data)\n",
        "\n",
        "            if len(response) < 100:\n",
        "                break\n",
        "\n",
        "            page += 1\n",
        "\n",
        "        return repos[:max_repos]\n",
        "\n",
        "def main():\n",
        "    token = \"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\"  # Replace with your actual GitHub token\n",
        "\n",
        "    # Initialize scraper\n",
        "    scraper = GitHubScraper(token)\n",
        "\n",
        "    # Search for users in Stockholm with >100 followers\n",
        "    users = scraper.search_users(location='Stockholm', min_followers=100)\n",
        "\n",
        "    # Save users to CSV\n",
        "    users_df = pd.DataFrame(users)\n",
        "    users_df.to_csv('users.csv', index=False)\n",
        "\n",
        "    # Get repositories for each user\n",
        "    all_repos = []\n",
        "    for user in users:\n",
        "        repos = scraper.get_user_repositories(user['login'])\n",
        "        all_repos.extend(repos)\n",
        "\n",
        "    # Save repositories to CSV\n",
        "    repos_df = pd.DataFrame(all_repos)\n",
        "    repos_df.to_csv('repositories.csv', index=False)\n",
        "\n",
        "    print(f\"Scraped {len(users)} users and {len(all_repos)} repositories\")\n",
        "\n",
        "    # Create README.md\n",
        "    with open('README.md', 'w') as f:\n",
        "        f.write(f\"\"\"# GitHub Users in Stockholm\n",
        "\n",
        "This repository contains data about GitHub users in Stockholm with over 100 followers and their repositories.\n",
        "\n",
        "## Files\n",
        "\n",
        "1. `users.csv`: Contains information about {len(users)} GitHub users in Stockholm with over 100 followers\n",
        "2. `repositories.csv`: Contains information about {len(all_repos)} public repositories from these users\n",
        "3. `fetch_users.py`: Python script used to collect this data\n",
        "\n",
        "## Data Collection\n",
        "\n",
        "- Data collected using GitHub API\n",
        "- Date of collection: {time.strftime('%Y-%m-%d')}\n",
        "- Only included users with 100+ followers\n",
        "- Up to 500 most recently pushed repositories per user\n",
        "\"\"\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXr8_isl2Ho8",
        "outputId": "60816af9-bc84-4b42-9a40-d0be5dae0453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scraped 410 users and 35432 repositories\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#downloading files\n",
        "from google.colab import files\n",
        "\n",
        "# Download the users.csv and repositories.csv files\n",
        "files.download('users.csv')\n",
        "files.download('repositories.csv')\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "id": "45Lo1qgY2mHl",
        "outputId": "df3e14be-fca3-4b8f-8bce-3f3af036d163"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_6abdb674-af7e-45ca-ac5e-738380ccd9ec\", \"users.csv\", 58708)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_7961fcab-f51a-46fd-a7fe-7f8bc8576e6a\", \"repositories.csv\", 2785240)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-1\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Sort the users by followers in descending order and get the top 5\n",
        "top_users = users_df.sort_values(by='followers', ascending=False).head(5)\n",
        "\n",
        "# Get the logins of the top users\n",
        "top_user_logins = ', '.join(top_users['login'].tolist())\n",
        "\n",
        "print(\"Top 5 users in Stockholm with the highest number of followers:\")\n",
        "print(top_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_BYkavKA5d8f",
        "outputId": "5c27c360-03d8-4f93-87e7-1138435fa3da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users in Stockholm with the highest number of followers:\n",
            "emmabostian, emilk, mpj, hrydgard, eriklindernoren\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "-51L_wZ27TWU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-2\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Convert 'created_at' to datetime\n",
        "users_df['created_at'] = pd.to_datetime(users_df['created_at'])\n",
        "\n",
        "# Get the top 5 earliest registered users\n",
        "earliest_users = users_df.nsmallest(5, 'created_at')\n",
        "\n",
        "# Get the login names in ascending order\n",
        "earliest_user_logins = ', '.join(earliest_users['login'].tolist())\n",
        "\n",
        "# Output the result\n",
        "print(\"Earliest registered users in Stockholm:\", earliest_user_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LmFmx_tC6qY6",
        "outputId": "f0cbcf4a-7d53-44b4-a931-a4d719929362"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Earliest registered users in Stockholm: Mange, kallepersson, fesplugas, etnt, pirelenito\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-3\n",
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out missing licenses\n",
        "licenses = repos_df['license_name'].dropna()\n",
        "\n",
        "# Count the occurrences of each license\n",
        "license_counts = licenses.value_counts()\n",
        "\n",
        "# Get the top 3 most popular licenses\n",
        "top_3_licenses = license_counts.head(3).index.tolist()\n",
        "\n",
        "# Output the result\n",
        "print(\"The 3 most popular licenses are:\", ', '.join(top_3_licenses))\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6wE9Ddc8-JyK",
        "outputId": "def16051-540b-47e0-b849-027b0326825e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The 3 most popular licenses are: mit, apache-2.0, other\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-4\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Clean up the company names\n",
        "users_df['company'] = users_df['company'].str.strip().str.lstrip('@').str.upper()\n",
        "\n",
        "# Count the occurrences of each company\n",
        "company_counts = users_df['company'].value_counts()\n",
        "\n",
        "# Get the company with the highest count\n",
        "most_common_company = company_counts.idxmax()\n",
        "most_common_count = company_counts.max()\n",
        "\n",
        "# Output the result\n",
        "print(\"The majority of developers work at:\", most_common_company)\n",
        "print(\"Number of developers at this company:\", most_common_count)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dUo2NzQn-VED",
        "outputId": "1e1c3b6b-0bad-473d-917c-b811a79d2ed8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The majority of developers work at: SPOTIFY\n",
            "Number of developers at this company: 21\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-5\n",
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out missing languages\n",
        "languages = repos_df['language'].dropna()\n",
        "\n",
        "# Count the occurrences of each language\n",
        "language_counts = languages.value_counts()\n",
        "\n",
        "# Get the most popular language\n",
        "most_popular_language = language_counts.idxmax()\n",
        "\n",
        "# Output the result\n",
        "print(\"The most popular programming language is:\", most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6xUfaz3p-s-e",
        "outputId": "0c03b370-5f06-49bf-982c-184fa8de6377"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The most popular programming language is: JavaScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-6\n",
        "import pandas as pd\n",
        "\n",
        "# Load users and repositories data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter users who joined after 2020\n",
        "users_after_2020 = users_df[pd.to_datetime(users_df['created_at']) > '2020-01-01']\n",
        "\n",
        "# Merge with repositories data to get repos only for users who joined after 2020\n",
        "repos_after_2020 = repos_df[repos_df['login'].isin(users_after_2020['login'])]\n",
        "\n",
        "# Filter out missing languages\n",
        "languages_after_2020 = repos_after_2020['language'].dropna()\n",
        "\n",
        "# Count occurrences of each language\n",
        "language_counts_after_2020 = languages_after_2020.value_counts()\n",
        "\n",
        "# Get the second most popular language\n",
        "second_most_popular_language = language_counts_after_2020.index[1]\n",
        "\n",
        "# Output the result\n",
        "print(\"The second most popular programming language among users who joined after 2020 is:\", second_most_popular_language)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W0_UGCq7-zM3",
        "outputId": "c28eab08-7aec-4504-db97-fb8d76727209"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The second most popular programming language among users who joined after 2020 is: TypeScript\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-7\n",
        "import pandas as pd\n",
        "\n",
        "# Load repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Filter out rows with missing language or zero stars\n",
        "repos_with_stars = repos_df[repos_df['stargazers_count'] > 0].dropna(subset=['language'])\n",
        "\n",
        "# Group by language and calculate the average star count per language\n",
        "avg_stars_per_language = repos_with_stars.groupby('language')['stargazers_count'].mean()\n",
        "\n",
        "# Find the language with the highest average stars\n",
        "top_language_by_avg_stars = avg_stars_per_language.idxmax()\n",
        "top_avg_stars = avg_stars_per_language.max()\n",
        "\n",
        "# Output the result\n",
        "print(\"The language with the highest average number of stars per repository is:\", top_language_by_avg_stars)\n",
        "print(\"Average stars per repository:\", top_avg_stars)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bJ9qigqJ-8Po",
        "outputId": "3c9d3886-7b14-4d76-9586-6640d35d5d6e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The language with the highest average number of stars per repository is: RAML\n",
            "Average stars per repository: 981.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-8\n",
        "import pandas as pd\n",
        "\n",
        "# Load users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate leader_strength\n",
        "users_df['leader_strength'] = users_df['followers'] / (1 + users_df['following'])\n",
        "\n",
        "# Sort by leader_strength in descending order and get the top 5 users\n",
        "top_leaders = users_df.sort_values(by='leader_strength', ascending=False).head(5)\n",
        "\n",
        "# Output the top 5 users' login in a comma-separated format\n",
        "top_leader_logins = \", \".join(top_leaders['login'])\n",
        "print(\"Top 5 users by leader_strength:\", top_leader_logins)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bBUbcrVy_Czh",
        "outputId": "9d0b9851-a20c-4235-df3e-1419ed11c89b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users by leader_strength: spotify, Mojang, fornwall, joearms, EmbarkStudios\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-9\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the correlation between followers and public_repos\n",
        "correlation = users_df['followers'].corr(users_df['public_repos'])\n",
        "\n",
        "# Print the correlation rounded to 3 decimal places\n",
        "print(\"Correlation between followers and public repositories:\", round(correlation, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VuPaCA2G_KnK",
        "outputId": "5548cff2-c7b8-4e89-c305-cb22be35f330"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Correlation between followers and public repositories: 0.035\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-10\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Define the independent (X) and dependent (Y) variables\n",
        "X = users_df['public_repos']\n",
        "Y = users_df['followers']\n",
        "\n",
        "# Add a constant to the independent variable for the intercept\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(Y, X).fit()\n",
        "\n",
        "# Get the slope (coefficient of public_repos)\n",
        "slope = model.params['public_repos']\n",
        "\n",
        "print(\"Estimated increase in followers per additional repository:\", round(slope, 3))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6I2Cf1l5_WWb",
        "outputId": "261edc52-cdfa-4ba5-cc4c-e88019ca144b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Estimated increase in followers per additional repository: 0.228\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-11\n",
        "import pandas as pd\n",
        "from scipy.stats import chi2_contingency\n",
        "\n",
        "# Load the CSV file\n",
        "csv_file = 'repositories.csv'  # Replace with the correct path\n",
        "\n",
        "# Load the CSV into a DataFrame\n",
        "df = pd.read_csv(csv_file)\n",
        "\n",
        "# Convert 'has_projects' and 'has_wiki' to boolean if necessary\n",
        "df['has_projects'] = df['has_projects'].astype(bool)\n",
        "df['has_wiki'] = df['has_wiki'].astype(bool)\n",
        "\n",
        "# Create a contingency table\n",
        "contingency_table = pd.crosstab(df['has_projects'], df['has_wiki'])\n",
        "\n",
        "# Perform Chi-Square test\n",
        "chi2, p, dof, expected = chi2_contingency(contingency_table)\n",
        "\n",
        "print(f\"Chi-Square Statistic: {chi2}\")\n",
        "print(f\"P-value: {p}\")\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "15l3UW-o_c7N",
        "outputId": "da72b76d-f645-47e9-f62b-da0850c0940b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Chi-Square Statistic: 4957.392403166435\n",
            "P-value: 0.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-12\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.linear_model import LinearRegression\n",
        "\n",
        "# Load the users data\n",
        "df = pd.read_csv('users.csv')\n",
        "\n",
        "# Remove users without bios and calculate the bio length in words\n",
        "df['bio_length'] = df['bio'].apply(lambda x: len(x.split()) if pd.notnull(x) else 0)\n",
        "df = df[df['bio_length'] > 0]  # Keep only users with non-empty bios\n",
        "\n",
        "# Prepare the data for regression\n",
        "X = df[['bio_length']].values  # Independent variable (bio length)\n",
        "y = df['followers'].values  # Dependent variable (followers)\n",
        "\n",
        "# Perform linear regression\n",
        "model = LinearRegression()\n",
        "model.fit(X, y)\n",
        "\n",
        "# Get the regression slope (coefficient)\n",
        "slope = model.coef_[0]\n",
        "\n",
        "# Print the slope rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I3CZemMr_tTm",
        "outputId": "9eeae341-5d59-4f4b-aee4-32c3c7d5ccba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on bio word count: 6.777\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-13\n",
        "import pandas as pd\n",
        "\n",
        "# Load the repositories data\n",
        "repos_df = pd.read_csv('repositories.csv')\n",
        "\n",
        "# Convert the 'created_at' column to datetime\n",
        "repos_df['created_at'] = pd.to_datetime(repos_df['created_at'])\n",
        "\n",
        "# Filter to keep only weekend entries (Saturday: 5, Sunday: 6)\n",
        "repos_df['day_of_week'] = repos_df['created_at'].dt.dayofweek\n",
        "weekend_repos = repos_df[repos_df['day_of_week'].isin([5, 6])]\n",
        "\n",
        "# Count repositories created by each user on weekends\n",
        "top_weekend_users = weekend_repos['login'].value_counts().head(5)\n",
        "\n",
        "# List of top 5 users' logins\n",
        "top_users_logins = ', '.join(top_weekend_users.index)\n",
        "print(f\"Top 5 users who created the most repositories on weekends: {top_users_logins}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KOTwsvsHAkA0",
        "outputId": "1d6785b1-43b8-4051-ed79-b2f577b98c64"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 users who created the most repositories on weekends: HaraldNordgren, Nyholm, lydell, linhduongtuan, LinusU\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-14\n",
        "import pandas as pd\n",
        "\n",
        "# Load the users data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Calculate the fraction of users with email addresses for hireable=true\n",
        "fraction_hireable = users_df[users_df['hireable'] == True]['email'].notnull().mean()\n",
        "\n",
        "# Calculate the fraction of users with email addresses for hireable=false\n",
        "fraction_non_hireable = users_df[users_df['hireable'] == False]['email'].notnull().mean()\n",
        "\n",
        "# Calculate the difference\n",
        "difference = fraction_hireable - fraction_non_hireable\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Difference in email sharing: {difference:.3f}\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Dm0YnPRkAr-G",
        "outputId": "50e02ff2-c4a4-4b2a-e542-d85e30a241cd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Difference in email sharing: 0.169\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-15\n",
        "import csv\n",
        "from collections import Counter\n",
        "\n",
        "# Counter to store surname frequencies\n",
        "surname_counter = Counter()\n",
        "\n",
        "# Open the users.csv file and read data\n",
        "with open('users.csv', 'r', encoding='utf-8') as file:\n",
        "    reader = csv.DictReader(file)\n",
        "\n",
        "    for row in reader:\n",
        "        name = row.get('name', '').strip()\n",
        "        if name:  # Ignore missing names\n",
        "            # Split the name by whitespace and get the last word as the surname\n",
        "            surname = name.split()[-1]\n",
        "            surname_counter[surname] += 1\n",
        "\n",
        "# Find the maximum frequency of surnames\n",
        "if surname_counter:\n",
        "    max_count = max(surname_counter.values())\n",
        "    # Get all surnames with the maximum frequency\n",
        "    most_common_surnames = [surname for surname, count in surname_counter.items() if count == max_count]\n",
        "    # Sort surnames alphabetically\n",
        "    most_common_surnames.sort()\n",
        "    # Output the result\n",
        "    print(f\"{', '.join(most_common_surnames)}: {max_count}\")\n",
        "else:\n",
        "    print(\"No names found.\")\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DdOAHhGLA2Px",
        "outputId": "49770a38-19d0-4c22-c64a-9789472ab88d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Gustafsson, Persson: 3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Q-16\n",
        "import pandas as pd\n",
        "import statsmodels.api as sm\n",
        "\n",
        "# Load the user data\n",
        "users_df = pd.read_csv('users.csv')\n",
        "\n",
        "# Drop rows without bios\n",
        "users_with_bio = users_df[users_df['bio'].notnull()]\n",
        "\n",
        "# Calculate the length of the bio in words\n",
        "users_with_bio['bio_word_count'] = users_with_bio['bio'].str.split().str.len()\n",
        "\n",
        "# Define the independent variable (bio word count) and dependent variable (followers)\n",
        "X = users_with_bio['bio_word_count']\n",
        "y = users_with_bio['followers']\n",
        "\n",
        "# Add a constant to the independent variable for the regression model\n",
        "X = sm.add_constant(X)\n",
        "\n",
        "# Fit the regression model\n",
        "model = sm.OLS(y, X).fit()\n",
        "\n",
        "# Get the regression slope (coefficient for bio_word_count)\n",
        "regression_slope = model.params['bio_word_count']\n",
        "\n",
        "# Print the result rounded to 3 decimal places\n",
        "print(f\"Regression slope of followers on bio word count: {regression_slope:.3f}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L1nL6QifBs_g",
        "outputId": "1eec6e9b-a1d1-4040-b629-c6189678a38f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Regression slope of followers on bio word count: 6.777\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-67-94a0eb396afd>:11: SettingWithCopyWarning: \n",
            "A value is trying to be set on a copy of a slice from a DataFrame.\n",
            "Try using .loc[row_indexer,col_indexer] = value instead\n",
            "\n",
            "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
            "  users_with_bio['bio_word_count'] = users_with_bio['bio'].str.split().str.len()\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UhKMsp3sQeKP"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}